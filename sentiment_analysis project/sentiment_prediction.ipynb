{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4383688c-e40f-49df-ab6b-7d6a4d0057c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "092eb9e9-cdf8-4705-9e98-c910750f88d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'data.csv'\n",
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ffc9170-954e-4704-aa50-d0db7138418d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Place of Review</th>\n",
       "      <th>Up Votes</th>\n",
       "      <th>Down Votes</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review text</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamal Suresh</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Certified Buyer, Chirakkal</td>\n",
       "      <td>889.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. S. Raja Srinivasan</td>\n",
       "      <td>Did not meet expectations</td>\n",
       "      <td>Certified Buyer, Dharmapuri</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Apr 2021</td>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suresh Narayanasamy</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Certified Buyer, Chennai</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quite O. K. , but nowadays  the quality of the...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHIK P A</td>\n",
       "      <td>Over priced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Apr 2016</td>\n",
       "      <td>Over pricedJust â?¹620 ..from retailer.I didn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Reviewer Name               Review Title  \\\n",
       "0            Kamal Suresh               Nice product   \n",
       "1       Flipkart Customer     Don't waste your money   \n",
       "2  A. S. Raja Srinivasan   Did not meet expectations   \n",
       "3     Suresh Narayanasamy                       Fair   \n",
       "4               ASHIK P A                Over priced   \n",
       "\n",
       "               Place of Review  Up Votes  Down Votes     Month  \\\n",
       "0   Certified Buyer, Chirakkal     889.0        64.0  Feb 2021   \n",
       "1   Certified Buyer, Hyderabad     109.0         6.0  Feb 2021   \n",
       "2  Certified Buyer, Dharmapuri      42.0         3.0  Apr 2021   \n",
       "3     Certified Buyer, Chennai      25.0         1.0       NaN   \n",
       "4                          NaN     147.0        24.0  Apr 2016   \n",
       "\n",
       "                                         Review text  Ratings  \n",
       "0  Nice product, good quality, but price is now r...        4  \n",
       "1  They didn't supplied Yonex Mavis 350. Outside ...        1  \n",
       "2  Worst product. Damaged shuttlecocks packed in ...        1  \n",
       "3  Quite O. K. , but nowadays  the quality of the...        3  \n",
       "4  Over pricedJust â?¹620 ..from retailer.I didn'...        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bc4f806-b1c1-4bb0-9753-71b51161cbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.dropna(subset = ['Review text'])\n",
    "text = text['Review text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a161fb08-d357-4d1f-89ba-4aa294d7b716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "def text_process(text):\n",
    "    text = str(text)\n",
    "    clean_text = re.sub(r'[^a-zA-Z0-9\\s]', '',text)\n",
    "    clean_text = clean_text.lower()\n",
    "    tokens = word_tokenize(clean_text)    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    clean_text = [token for token in tokens if token not in stop_words]\n",
    "    # clean_text = [lemmatizer.lemmatize(text) for text in clean_text]  \n",
    "    return \" \".join(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58d59889-5bca-40fe-8e56-21d31ba049de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['Review text'].apply(text_process)\n",
    "text = df['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8d99bc0-d09f-432a-8a9e-bdf39ec5c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "def sentiment_score(text):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment_scores = sia.polarity_scores(text)\n",
    "    compound_score = sentiment_scores['compound']\n",
    "    sentiment = 'Positive' if compound_score > 0 else 'Negative'\n",
    "    return sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b231c419-edeb-4ea6-87f2-4840a03636ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.6 s, sys: 61.3 ms, total: 21.6 s\n",
      "Wall time: 21.7 s\n"
     ]
    }
   ],
   "source": [
    "%time df['Sentiment'] = text.apply(lambda x: pd.Series(sentiment_score(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "682ebe06-1fab-407c-a56e-ff2b1ff800a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "Negative    4377\n",
       "Positive    4141\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "123f6706-d86a-425b-b190-9ad0ee0c5b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = text\n",
    "y = df['Sentiment']\n",
    "y = y.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "271ed196-602e-4fc3-ab43-0a73a031d6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6388,), (2130,), (6388,), (2130,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size= 0.25, random_state = 42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27e05791-3d43-489e-b306-70dce8fc3c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/12 19:35:31 INFO mlflow.tracking.fluent: Experiment with name 'feedback_sentiment_prediction' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "import mlflow \n",
    "mlflow.set_experiment(\"feedback_sentiment_prediction\")\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d04a8a39-826d-4656-b144-993670045824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import joblib \n",
    "from joblib import Memory\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28001da2-ee04-485f-998c-36543631570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedir = '.cache'\n",
    "memory = Memory(location=cachedir, verbose=0)\n",
    "\n",
    "pipelines = {\n",
    "    'logistic_regression': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ], memory=memory),\n",
    "    'decision_tree': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', DecisionTreeClassifier())\n",
    "    ], memory=memory),\n",
    "    'random-forest': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ], memory = memory),\n",
    "    'SVC' : Pipeline([\n",
    "        ('vectorization',CountVectorizer()),\n",
    "        ('classifier', SVC())\n",
    "    ], memory = memory),\n",
    "    'naive_bayes': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ], memory=memory),\n",
    "}\n",
    "\n",
    "param_grids = {    \n",
    "    'logistic_regression': [\n",
    "        {\n",
    "            'classifier__C': [0.1, 1, 10], \n",
    "            'classifier__solver': ['saga'],\n",
    "        }\n",
    "    ],\n",
    "    'decision_tree': [\n",
    "        {\n",
    "            'classifier__max_depth': [None, 5, 10]\n",
    "        }\n",
    "    ],\n",
    "    'random-forest': [\n",
    "        {\n",
    "            'classifier__n_estimators': [100, 200, 300],\n",
    "            'classifier__max_depth': [None, 10, 20],\n",
    "            'classifier__max_features': ['auto']\n",
    "        }\n",
    "    ],\n",
    "    'SVC':[\n",
    "        {\n",
    "            'classifier__C': [0.1, 1, 10],\n",
    "            'classifier__kernel': ['linear', 'rbf'],\n",
    "            'classifier__degree': [2, 3, 4]\n",
    "        }\n",
    "    ],\n",
    "    \n",
    "    'naive_bayes': [\n",
    "        {\n",
    "            'classifier__alpha': [1, 10]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4be3492f-30c2-4888-94ca-be5cddea4453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- logistic_regression -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/12 19:35:31 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/12 19:35:36 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.67 s, sys: 849 ms, total: 4.52 s\n",
      "Wall time: 4.59 s\n",
      "Score on Test Data:  0.9760994263862334\n",
      "----- decision_tree -----\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/12 19:35:40 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.97 s, sys: 404 ms, total: 3.37 s\n",
      "Wall time: 3.58 s\n",
      "Score on Test Data:  0.9773584905660377\n",
      "----- random-forest -----\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/12 19:36:18 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.3 s, sys: 2.59 s, total: 38.9 s\n",
      "Wall time: 38 s\n",
      "Score on Test Data:  0.9720246562351826\n",
      "----- SVC -----\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/12 19:37:13 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.8 s, sys: 2.17 s, total: 55.9 s\n",
      "Wall time: 55 s\n",
      "Score on Test Data:  0.9834358731661144\n",
      "----- naive_bayes -----\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "CPU times: user 1.41 s, sys: 1.63 s, total: 3.04 s\n",
      "Wall time: 2.98 s\n",
      "Score on Test Data:  0.9295774647887324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "scorer = make_scorer(f1_score, pos_label='Positive')\n",
    "best_models = {}\n",
    "\n",
    "for p in pipelines.keys():\n",
    "    print(\"-\"*5, p, \"-\"*5)\n",
    "    grid_search = GridSearchCV(estimator=pipelines[p], \n",
    "                               param_grid=param_grids[p], \n",
    "                               cv=5, \n",
    "                               scoring= scorer, \n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                              )\n",
    "    mlflow.sklearn.autolog(max_tuning_runs = None)\n",
    "    with mlflow.start_run() as run:\n",
    "        %time grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_models[p] = grid_search.best_estimator_\n",
    "    \n",
    "    print('Score on Test Data: ', grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57af8b9c-da7c-4ff5-b5a7-1ec73d996afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- logistic_regression ----------\n",
      "Pipeline(memory=Memory(location=.cache/joblib),\n",
      "         steps=[('vectorization', CountVectorizer()),\n",
      "                ('classifier', LogisticRegression(C=10, solver='saga'))])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------- decision_tree ----------\n",
      "Pipeline(memory=Memory(location=.cache/joblib),\n",
      "         steps=[('vectorization', CountVectorizer()),\n",
      "                ('classifier', DecisionTreeClassifier())])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------- random-forest ----------\n",
      "Pipeline(memory=Memory(location=.cache/joblib),\n",
      "         steps=[('vectorization', CountVectorizer()),\n",
      "                ('classifier',\n",
      "                 RandomForestClassifier(max_features='auto',\n",
      "                                        n_estimators=200))])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------- SVC ----------\n",
      "Pipeline(memory=Memory(location=.cache/joblib),\n",
      "         steps=[('vectorization', CountVectorizer()),\n",
      "                ('classifier', SVC(C=10, degree=2, kernel='linear'))])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "---------- naive_bayes ----------\n",
      "Pipeline(memory=Memory(location=.cache/joblib),\n",
      "         steps=[('vectorization', CountVectorizer()),\n",
      "                ('classifier', MultinomialNB(alpha=1))])\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name, model in best_models.items():\n",
    "    print('-'*10, name, '-' * 10)\n",
    "    print(model)\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34cd7ca1-a5ce-44d9-8e40-700b3129813a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** logistic_regression **********\n",
      "CPU times: user 3.97 ms, sys: 35 µs, total: 4 ms\n",
      "Wall time: 4 ms\n",
      "F1 Test Score  0.9760994263862334\n",
      "Model Size: 73433 Bytes\n",
      "********** decision_tree **********\n",
      "CPU times: user 4.28 ms, sys: 56 µs, total: 4.34 ms\n",
      "Wall time: 4.34 ms\n",
      "F1 Test Score  0.9773584905660377\n",
      "Model Size: 73544 Bytes\n",
      "********** random-forest **********\n",
      "CPU times: user 119 ms, sys: 290 µs, total: 119 ms\n",
      "Wall time: 119 ms\n",
      "F1 Test Score  0.9720246562351826\n",
      "Model Size: 25988960 Bytes\n",
      "********** SVC **********\n",
      "CPU times: user 37.9 ms, sys: 60 µs, total: 38 ms\n",
      "Wall time: 38 ms\n",
      "F1 Test Score  0.9834358731661144\n",
      "Model Size: 127525 Bytes\n",
      "********** naive_bayes **********\n",
      "CPU times: user 3.8 ms, sys: 9 µs, total: 3.81 ms\n",
      "Wall time: 3.81 ms\n",
      "F1 Test Score  0.9295774647887324\n",
      "Model Size: 152630 Bytes\n"
     ]
    }
   ],
   "source": [
    "for name, model in best_models.items():\n",
    "    print(\"*\"*10, name, \"*\"*10)\n",
    "    joblib.dump(model, f'best_models/{name}.pkl')\n",
    "    model = joblib.load(f'best_models/{name}.pkl')\n",
    "    %time y_test_pred = model.predict(X_test)\n",
    "    print(\"F1 Test Score \", f1_score(y_test, y_test_pred, pos_label='Positive'))\n",
    "    print(\"Model Size:\", os.path.getsize(f'best_models/{name}.pkl'), \"Bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cd371c-e888-4e83-a4f3-2da9fdad5879",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('best_models/SVC.pkl')\n",
    "new_data = [input('enter text')]\n",
    "model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0024266b-b4e6-4b7e-b792-b4579ce8481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('best_models/SVC.pkl')\n",
    "new_data = [input('enter text')]\n",
    "model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605f05d5-db50-4492-b3fc-14aeb2bb1b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c71c76e-1e34-4c07-9f98-3f06b15f0059",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('badminton_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50521eae-ec6f-47e8-8923-e05261263942",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
